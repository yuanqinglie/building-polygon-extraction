# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FK-ltoaKy0p55e58DIfDWHxAujIBy7zX
"""

class CFPE(nn.Module):
    """Crossing-Feature Primitives Enhancement module (ResNet50 adapted version)"""
    def __init__(self, in_channels_l2: int = 256, in_channels_l3: int = 256,
                 in_channels_l4: int = 256, in_channels_l5: int = 256,
                 out_channels: int = 256):
        super().__init__()
        # Unify channel counts across layers - input is now adapted d_model
        self.conv_l2 = nn.Conv2d(in_channels_l2, out_channels, kernel_size=1) if in_channels_l2 != out_channels else nn.Identity()
        self.conv_l3 = nn.Conv2d(in_channels_l3, out_channels, kernel_size=1) if in_channels_l3 != out_channels else nn.Identity()
        self.conv_l4 = nn.Conv2d(in_channels_l4, out_channels, kernel_size=1) if in_channels_l4 != out_channels else nn.Identity()
        self.conv_l5 = nn.Conv2d(in_channels_l5, out_channels, kernel_size=1) if in_channels_l5 != out_channels else nn.Identity()

        self.conv1x1 = nn.Conv2d(out_channels, out_channels, kernel_size=1)

        # Sobel operator initialization
        self.sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)
        self.sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)

        # Depthwise separable convolution
        self.conv_ix = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, groups=out_channels)
        self.conv_iy = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, groups=out_channels)

        self.final_conv = nn.Conv2d(out_channels, out_channels, kernel_size=1)

    def forward(self, L2: torch.Tensor, L3: torch.Tensor, L4: torch.Tensor, L5: torch.Tensor) -> torch.Tensor:
        # Step 1: Check input dimensions
        assert L2.dim() == 4 and L3.dim() == 4 and L4.dim() == 4 and L5.dim() == 4

        # Step 2: Unify channel counts (if needed)
        L2 = self.conv_l2(L2)
        L3 = self.conv_l3(L3)
        L4 = self.conv_l4(L4)
        L5 = self.conv_l5(L5)

        # Step 3: Shallow feature fusion (ensure spatial dimension matching)
        downsampled_L2 = F.avg_pool2d(L2, 2, 2)  # [B, C, 128, 128] (matches L3 spatial dimensions)
        Xl = self.conv1x1(L3 + downsampled_L2)  # [B, C, 128, 128] (4D)

        # Step 4: Deep feature fusion
        upsampled_L5 = F.interpolate(L5, size=L4.shape[2:], mode='bilinear')  # [B, C, 64, 64] (matches L4)
        Xh = self.conv1x1(L4 + upsampled_L5)  # [B, C, 64, 64] (4D)

        # Step 5: Affinity matrix calculation (fix dimensions)
        avg_Xl = torch.mean(Xl, dim=[2, 3])  # [B, C] (global pooling, temporarily loses spatial dimensions)
        avg_Xh = torch.mean(Xh, dim=[2, 3])  # [B, C]
        Aff = F.softmax(torch.matmul(avg_Xl.unsqueeze(2), avg_Xh.unsqueeze(1)), dim=-1)  # [B, C, C]

        # Step 6: Shallow feature refinement (critical: preserve spatial dimensions)
        Xl_reshaped = Xl.permute(0, 2, 3, 1)  # [B, 128, 128, C] (preserves H=128, W=128)
        Xl_refined = torch.matmul(Xl_reshaped, Aff)  # [B, 128, 128, C] (still has spatial dimensions)
        Xl_refined = Xl_refined.permute(0, 3, 1, 2)  # [B, C, 128, 128] (restore 4D)
        Xl_refined = self.conv1x1(Xl_refined)  # 4D input, normal convolution

        # Step 7: Final feature fusion (maintain 4D)
        upsampled_Xh = F.interpolate(Xh, size=Xl_refined.shape[2:], mode='bilinear')  # [B, C, 128, 128]
        Z_xlxh = Xl_refined + upsampled_Xh  # [B, C, 128, 128] (4D)

        # Step 8: Corner/edge feature extraction (ensure 4D input)
        Gx = self.conv_ix(Z_xlxh)  # [B, C, 128, 128] (4D)
        Gy = self.conv_iy(Z_xlxh)  # [B, C, 128, 128] (4D)

        # Step 9: Gaussian smoothing (input must be 4D)
        Ix2 = Gx **2  # [B, C, 128, 128]
        Iy2 = Gy** 2  # [B, C, 128, 128]
        Ixy = Gx * Gy  # [B, C, 128, 128]
        Ix2_smoothed = gaussian_smooth(Ix2)  # Call fixed Gaussian smoothing
        Iy2_smoothed = gaussian_smooth(Iy2)
        Ixy_smoothed = gaussian_smooth(Ixy)

        # Subsequent steps maintain 4D output
        FHa = harris_response(Ix2_smoothed, Iy2_smoothed, Ixy_smoothed)  # 4D
        Fso = torch.sqrt(Gx**2 + Gy**2 + 1e-8)  # 4D
        Zf = self.final_conv(Z_xlxh + FHa + Fso)  # [B, C, 128, 128] (4D)

        return Zf