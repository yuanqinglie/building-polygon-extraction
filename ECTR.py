# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FK-ltoaKy0p55e58DIfDWHxAujIBy7zX
"""

class ECTR(nn.Module):
    """Edge-context-guided Topology Reconstruction module (fixed version)"""
    def __init__(self, d_model: int = 256, num_vertices_per_building: int = 8, top_e: int = 16):
        super().__init__()
        self.num_vertices = num_vertices_per_building
        self.top_e = top_e
        self.d_model = d_model

        # Edge confidence prediction
        self.score_mlp = nn.Sequential(
            nn.Linear(2 * d_model, d_model),
            nn.ReLU(),
            nn.Linear(d_model, 1)
        )

        # Multi-scale edge feature sampling
        self.msp = nn.ModuleList([
            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),
            nn.MaxPool2d(kernel_size=5, stride=1, padding=2),
            nn.MaxPool2d(kernel_size=7, stride=1, padding=3)
        ])
        self.msp_norm = nn.LayerNorm(d_model)

        # Edge attention calculation - fix: ensure correct input dimensions
        self.edge_attn = DeformableAttention(d_model, n_heads=8)  # Add n_heads parameter

        # Fix: Ensure input-output dimensions of linear layers match
        self.mlp_qe = nn.Linear(d_model, d_model)
        self.mlp_ke = nn.Linear(d_model, d_model)
        self.mlp_ve = nn.Linear(d_model, d_model)

        # Adjacency matrix prediction
        self.mlp_clo = nn.Linear(d_model, num_vertices_per_building)
        self.mlp_cou = nn.Linear(d_model, num_vertices_per_building)

    def forward(self, Q: torch.Tensor, Drc: torch.Tensor, Zf: torch.Tensor) -> torch.Tensor:
        B, K, C = Q.shape
        Nv = self.num_vertices

        # Step 1: Predict edge confidence and filter Top-e edges
        vertices = Q.unsqueeze(2).expand(B, K, Nv, C)  # (B, K, Nv, C)
        vertices_i = vertices.unsqueeze(3).expand(B, K, Nv, Nv, C)  # (B, K, Nv, Nv, C)
        vertices_j = vertices.unsqueeze(2).expand(B, K, Nv, Nv, C)  # (B, K, Nv, Nv, C)

        pairs = torch.cat([vertices_i, vertices_j], dim=-1)  # (B, K, Nv, Nv, 2*C)

        # Calculate edge scores
        edge_scores = self.score_mlp(pairs).squeeze(-1)  # (B, K, Nv, Nv)

        # Select top-e edges
        edge_scores_flat = edge_scores.reshape(B, K, -1)
        top_e_values, top_e_indices = torch.topk(edge_scores_flat, k=self.top_e, dim=-1)  # (B, K, top_e)

        # Step 2: Extract edge context features
        Drc_flat = Drc.reshape(B, K, Nv, 2)
        idx_i = top_e_indices // Nv  # (B, K, top_e)
        idx_j = top_e_indices % Nv   # (B, K, top_e)

        # Collect corresponding coordinates
        coords_i = torch.gather(
            Drc_flat,
            dim=2,
            index=idx_i.unsqueeze(-1).expand(B, K, self.top_e, 2)
        )  # (B, K, top_e, 2)
        coords_j = torch.gather(
            Drc_flat,
            dim=2,
            index=idx_j.unsqueeze(-1).expand(B, K, self.top_e, 2)
        )  # (B, K, top_e, 2)

        edge_mid = (coords_i + coords_j) / 2  # (B, K, top_e, 2)

        # Multi-scale edge feature sampling
        edge_feats = []
        for pool in self.msp:
            zf_pooled = pool(Zf)  # (B, C, H, W)

            # Reshape edge coordinates for grid_sample
            edge_mid_reshaped = edge_mid.reshape(B, -1, 1, 2)  # (B, K*top_e, 1, 2)

            # Bilinear sampling
            feat_sampled = F.grid_sample(
                zf_pooled,
                edge_mid_reshaped,
                mode='bilinear',
                align_corners=False
            )  # (B, C, K*top_e, 1)

            feat_sampled = feat_sampled.squeeze(-1).permute(0, 2, 1)  # (B, K*top_e, C)
            feat_sampled = feat_sampled.reshape(B, K, self.top_e, C)  # (B, K, top_e, C)
            edge_feats.append(feat_sampled)

        # Feature fusion
        edge_feat = torch.stack(edge_feats, dim=0).mean(dim=0)  # (B, K, top_e, C)
        edge_feat = self.msp_norm(edge_feat)

        # Step 3: Edge attention and adjacency matrix prediction
        Qe = self.mlp_qe(Q.unsqueeze(2).expand(B, K, Nv, C).reshape(B, K*Nv, C))  # (B, K*Nv, C)
        Ke = self.mlp_ke(edge_feat.reshape(B, K*self.top_e, C))  # (B, K*top_e, C)
        Ve = self.mlp_ve(edge_feat.reshape(B, K*self.top_e, C))  # (B, K*top_e, C)

        # Edge attention calculation
        EAtt = self.edge_attn(Qe, Ke, Ve)  # (B, K*Nv, C)
        EAtt = EAtt.reshape(B, K, Nv, C)   # (B, K, Nv, C)

        # Predict adjacency matrix
        Aclo = self.mlp_clo(EAtt)  # (B, K, Nv, Nv)
        Acou = self.mlp_cou(EAtt)  # (B, K, Nv, Nv)
        SA = Aclo + Acou.transpose(-2, -1)  # Symmetrize

        return SA