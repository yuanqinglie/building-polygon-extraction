# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FK-ltoaKy0p55e58DIfDWHxAujIBy7zX
"""

import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
import torchvision.transforms as T


# --------------------------- Test helper functions ---------------------------
def preprocess_image(image_path: str, img_size: Tuple[int, int] = (512, 512)) -> torch.Tensor:
    """Preprocess input image: resize -> normalize -> convert to Tensor"""
    transform = T.Compose([
        T.Resize(img_size),
        T.ToTensor(),  # Convert to (C, H, W) and normalize to [0,1]
        T.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean
                    std=[0.229, 0.224, 0.225])    # ImageNet standard deviation
    ])
    image = Image.open(image_path).convert('RGB')
    input_tensor = transform(image).unsqueeze(0)  # Add batch dimension (1, 3, 512, 512)
    return input_tensor, image


def postprocess_vertices(vertices: torch.Tensor, img_size: Tuple[int, int] = (512, 512)) -> np.ndarray:
    """Map normalized vertex coordinates back to original image size"""
    # Model output coordinates are usually normalized to [-1, 1], need to map to [0, img_size]
    vertices = (vertices + 1) * 0.5  # Convert to [0, 1]
    vertices[:, :, :, 0] *= img_size[1]  # Width direction
    vertices[:, :, :, 1] *= img_size[0]  # Height direction
    return vertices.cpu().detach().numpy()


def visualize_results(image, vertices, confidence, adj_matrix, threshold=0.5, top_k=3):
    """Visualize prediction results: original image + high-confidence polygons"""
    plt.figure(figsize=(10, 10))
    plt.imshow(image)

    # Filter high-confidence building instances (by average vertex confidence)
    batch_size, num_queries, num_vertices, _ = vertices.shape
    avg_confidence = confidence.mean(dim=2).squeeze(-1)  # (B, K)
    top_indices = torch.topk(avg_confidence[0], k=top_k, dim=0)[1].cpu().numpy()  # Get top-k instances

    for idx in top_indices:
        # Filter high-confidence vertices in this instance
        verts = vertices[0, idx]  # (Nv, 2)
        conf = confidence[0, idx].squeeze(-1).cpu().numpy()  # (Nv,)
        valid_mask = conf > threshold  # Filter low-confidence vertices
        valid_verts = verts[valid_mask]

        if len(valid_verts) < 3:  # Need at least 3 vertices to form a polygon
            continue

        # Connect vertices according to adjacency matrix (take highest-scoring edges)
        adj = adj_matrix[0, idx].cpu().detach().numpy()  # (Nv, Nv)
        polygon = []
        current = np.argmax(conf)  # Start from most confident vertex
        visited = set()

        for _ in range(len(valid_verts)):
            if current in visited:
                break
            visited.add(current)
            polygon.append(valid_verts[current])
            # Find next most likely connected vertex
            next_idx = np.argmax(adj[current][valid_mask])
            current = np.where(valid_mask)[0][next_idx]

        # Draw polygon
        if len(polygon) >= 3:
            poly = Polygon(polygon, fill=False, edgecolor='red', linewidth=2)
            plt.gca().add_patch(poly)
            # Mark vertices
            for (x, y) in polygon:
                plt.scatter(x, y, c='blue', s=20)

    plt.axis('off')
    plt.show()


# --------------------------- Model test main function ---------------------------
def test_model(image_path: str, checkpoint_path: Optional[str] = None):
    """Test model inference pipeline"""
    # 1. Initialize model
    model = BuildingPolygonNet(
        encoder_type="resnet50",
        encoder_channels=[256, 512, 1024, 2048],
        d_model=256,
        num_queries=100,
        num_vertices=42,
        top_e=120,
        pretrained=True
    )
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    # 2. Load weights (optional)
    if checkpoint_path:
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()  # Switch to evaluation mode

    # 3. Preprocess input image (512x512x3)
    input_tensor, raw_image = preprocess_image(image_path, img_size=(512, 512))
    input_tensor = input_tensor.to(device)

    # 4. Model inference
    with torch.no_grad():  # Disable gradient calculation to speed up inference
        vertices, adj_matrix, confidence = model(input_tensor)

    # 5. Postprocess results
    vertices = postprocess_vertices(vertices)  # Map back to image coordinates

    # 6. Output result information
    print(f"Input image size: {raw_image.size}")
    print(f"Vertex coordinate shape: {vertices.shape} (B, K, Nv, 2)")
    print(f"Edge adjacency matrix shape: {adj_matrix.shape} (B, K, Nv, Nv)")
    print(f"Vertex confidence shape: {confidence.shape} (B, K, Nv, 1)")
    print(f"Average confidence of highest-confidence instance: {confidence.mean(dim=2).max().item():.4f}")

    # 7. Visualize results
    visualize_results(raw_image, vertices, confidence, adj_matrix, threshold=0.5)

    return {
        "vertices": vertices,          # Polygon vertex coordinates (1, 100, 8, 2)
        "adjacency_matrix": adj_matrix.cpu().detach().numpy(),  # Edge adjacency matrix (1, 100, 8, 8)
        "confidence": confidence.cpu().detach().numpy()          # Vertex confidence (1, 100, 8, 1)
    }


# --------------------------- Test execution ---------------------------
if __name__ == "__main__":
    # Replace with your test image path
    test_image_path = "/content/drive/MyDrive/test-WHU/image/0005.TIF"  # Input image size should be (512, 512, 3)
    # Optional: Replace with trained model weight path
    checkpoint_path = None  # "model_checkpoint.pth"

    # Execute test
    results = test_model(test_image_path, checkpoint_path)

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.ops as ops